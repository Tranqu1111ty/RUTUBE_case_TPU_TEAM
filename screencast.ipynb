{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c42e3ebc",
   "metadata": {},
   "source": [
    " # Представленный .ipynb файл демонстрирует алгоритм работы на примере одного видео"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ffccc",
   "metadata": {},
   "source": [
    "## Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d08451c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\druzh\\Project_python\\venv\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Не найдена указанная процедура'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from video2text import video_dataframe\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.translate import meteor\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.nist_score import sentence_nist\n",
    "from collections import Counter\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import GPT2Tokenizer, T5ForConditionalGeneration\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259be683",
   "metadata": {},
   "source": [
    "# Работа с видеорядом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886fb83",
   "metadata": {},
   "source": [
    "## Открываем файл с классами для модели ResNet50 на русском языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9d2923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_classes_ru.pickle', 'rb') as handle:\n",
    "    imagenet_classes_ru = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c86c0b0",
   "metadata": {},
   "source": [
    " ## Функция проверки пересечения прямоугольников, описывающих контуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c6d9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    return not (x1 + w1 < x2 or x2 + w2 < x1 or y1 + h1 < y2 or y2 + h2 < y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b2bcb",
   "metadata": {},
   "source": [
    "## Функция объединения контуров (поскольку выделяется множество небольших контуров, не несущих информации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8fdc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_contours(contours):\n",
    "    new_contours = []\n",
    "    skip = set()\n",
    "    for i in range(len(contours)):\n",
    "        if i in skip:\n",
    "            continue\n",
    "        contour1 = contours[i]\n",
    "        box1 = cv2.boundingRect(contour1)\n",
    "        union = None\n",
    "        for j in range(i + 1, len(contours)):\n",
    "            contour2 = contours[j]\n",
    "            box2 = cv2.boundingRect(contour2)\n",
    "            if is_overlapping(box1, box2):\n",
    "                skip.add(j)\n",
    "                if union is None:\n",
    "                    union = np.concatenate((contour1, contour2))\n",
    "                else:\n",
    "                    union = np.concatenate((union, contour2))\n",
    "        if union is None:\n",
    "            new_contours.append(contour1)\n",
    "        else:\n",
    "            new_contours.append(union)\n",
    "    return new_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243577c9",
   "metadata": {},
   "source": [
    "## Обработка изображений (Фильтр Гаусса, Оператор Canny, cv2.findContours, Нарезка по контурам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f6a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image_folder, output_folder, min_contour_area=0):\n",
    "    print('Processing images...')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "\n",
    "        mean_val = np.mean(img_gray)\n",
    "        std_dev = np.std(img_gray)\n",
    "\n",
    "        lower_threshold = mean_val - std_dev\n",
    "        upper_threshold = mean_val + std_dev\n",
    "\n",
    "        edges = cv2.Canny(img_gray, lower_threshold, upper_threshold * 4.5)\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = union_contours(contours)\n",
    "\n",
    "        for index, contour in enumerate(contours):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w * h < min_contour_area:\n",
    "                continue\n",
    "            cropped_img = image[y:y + h, x:x + w]\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_parts_{index}.jpg\")\n",
    "            cv2.imwrite(output_path, cropped_img)\n",
    "\n",
    "        shutil.copy(image_path, os.path.join(output_folder, f\"{os.path.basename(image_path)}\"))\n",
    "\n",
    "    print('Processing images - DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26459865",
   "metadata": {},
   "source": [
    "## Классификация изображений, нарезанных ранее при помощи модели ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9fdf2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(folder_path, folder_number):\n",
    "    print('Images classification...')\n",
    "    model3 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "    model3.eval()\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            input_image = Image.open(file_path)\n",
    "            input_tensor = preprocess(input_image)\n",
    "            input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model3(input_batch)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            class_name = imagenet_classes_ru.get(predicted.item())\n",
    "            predictions.append(class_name)\n",
    "\n",
    "    predictions_variable_name = f'predictions_{folder_number}'\n",
    "    output_filename = f'Objects_{folder_number}.txt'\n",
    "    with open(output_filename, 'w') as file:\n",
    "        for prediction in predictions:\n",
    "            file.write(f'{prediction}\\n')\n",
    "\n",
    "    # print('Images classification - DONE')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ce2b0",
   "metadata": {},
   "source": [
    "## Обработка видео (Избавление от неинформативных кадров с помощью гистограмм изображений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fb5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, threshold=0.96):\n",
    "    # print('Processing video...')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    prev_hist = None\n",
    "    count = 0\n",
    "\n",
    "    frames_dir = video_path.replace('.mp4', '')\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if count % fps == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "            cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX, -1)\n",
    "\n",
    "            if count == 0:\n",
    "                frame_filename = f'frame_0.jpg'\n",
    "                frame_filepath = os.path.join(frames_dir, frame_filename)\n",
    "                cv2.imwrite(frame_filepath, frame, [cv2.IMWRITE_JPEG_QUALITY, 70])\n",
    "\n",
    "            elif prev_hist is not None:\n",
    "                correlation = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)\n",
    "                if correlation < threshold:\n",
    "                    frame_filename = f'frame_{int(count / fps)}.jpg'\n",
    "                    frame_filepath = os.path.join(frames_dir, frame_filename)\n",
    "                    cv2.imwrite(frame_filepath, frame, [cv2.IMWRITE_JPEG_QUALITY, 70])\n",
    "\n",
    "            prev_hist = hist\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    # print('Processing video - DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c6fa2",
   "metadata": {},
   "source": [
    "## Декоратор функций работы с видеорядом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e5026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_dataframe(path2v, video_number, threshold=0.96, max_rectangle=10000):\n",
    "    video_path = f'{path2v}{video_number}'\n",
    "    images_folder = f'{path2v}{video_number}'.replace(\".mp4\", '')\n",
    "    parts_folder = f'{path2v}{video_number}_parts'.replace(\".mp4\", '')\n",
    "\n",
    "    process_video(video_path, threshold)\n",
    "    process_images(images_folder, parts_folder, max_rectangle)\n",
    "    data_info = classify_images(parts_folder, video_number)\n",
    "\n",
    "    shutil.rmtree(parts_folder)\n",
    "    shutil.rmtree(images_folder)\n",
    "\n",
    "    return data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5bfc71",
   "metadata": {},
   "source": [
    "## Дополнительный фильтр для извлечения топ слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1598b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_list(words):\n",
    "    word_counts = Counter(words)\n",
    "    top_10_words = word_counts.most_common(min(10, len(word_counts)))\n",
    "\n",
    "    only_words = [word for word, count in top_10_words]\n",
    "\n",
    "    return only_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49515251",
   "metadata": {},
   "source": [
    "# Работа с транскрипциями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8031d8",
   "metadata": {},
   "source": [
    "## Функция для удаления временных меток из транскрипции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f38ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_timestamps(text):\n",
    "    text = text.split(\"] \")[1:]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512739d0",
   "metadata": {},
   "source": [
    "## Считывание транскрипции в единый массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a48de1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_stt(stt_name):\n",
    "    with open(f\"./train_stt/{stt_name}\", 'r', encoding=\"utf_8_sig\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [del_timestamps(line.strip()) for line in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84741f3b",
   "metadata": {},
   "source": [
    "## Фильтрация ненормативной лексики и предложений малых размеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c81c88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus_(data, corpus_index):\n",
    "    data[\"stt\"] = data[\"stt_name\"].apply(ret_stt)\n",
    "    txt = data[\"stt\"][13]\n",
    "\n",
    "    tmp = []\n",
    "    flag = 0\n",
    "\n",
    "    for i in txt:\n",
    "        for j in i:\n",
    "            if j == '*':\n",
    "                flag = 1\n",
    "            else:\n",
    "                continue\n",
    "        if flag == 0 and len(i.split()) > 3:\n",
    "            tmp.append(i)\n",
    "        else:\n",
    "            flag = 0\n",
    "\n",
    "    return pd.Series(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1623e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data = data.iloc[[13]]\n",
    "    data[\"stt_sum\"] = [process_corpus_(data, i) for i in range(data.shape[0])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e779ff9",
   "metadata": {},
   "source": [
    "## Подключение моделей ruBert и FRED-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a79e5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(50364, 1536)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(50364, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 24)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(50364, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 24)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50364, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('content/rubert_cased_L-12_H-768_A-12_pt')\n",
    "model = BertModel.from_pretrained('content/rubert_cased_L-12_H-768_A-12_pt', output_hidden_states=True)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "tokenizer1 = GPT2Tokenizer.from_pretrained('ai-forever/FRED-T5-1.7B', eos_token='</s>')\n",
    "model1 = T5ForConditionalGeneration.from_pretrained('ai-forever/FRED-T5-1.7B')\n",
    "device = 'cpu'\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968b989",
   "metadata": {},
   "source": [
    "## Класс-обертка для работы с моделью ruBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9036dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.text = X\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=150)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.text.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        output = self.text[index]\n",
    "        output = self.tokenize(output)\n",
    "        return {k: v.reshape(-1) for k, v in output.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddd80a",
   "metadata": {},
   "source": [
    "## Функция для получения эмбеддингов предложений из предпоследнего слоя ruBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89f16950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output['last_hidden_state']\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2bcbe",
   "metadata": {},
   "source": [
    "## Главный алгоритм (ужатие пространства, кластеризация, генерация и последующая фильтрация описания, а также switch case для выбора модели исходя из данных в видео -есть транскрипция или нет-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1429fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(corpus, video_name, path_2_video):\n",
    "    eval_ds = CustomDataset(corpus)\n",
    "    eval_dataloader = DataLoader(eval_ds, batch_size=10)\n",
    "    if len(corpus) > 50:\n",
    "\n",
    "        embeddings = torch.Tensor().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for n_batch, batch in enumerate(tqdm(eval_dataloader)):\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                embeddings = torch.cat([embeddings, mean_pooling(outputs, batch['attention_mask'])])\n",
    "            embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "        pca = PCA(n_components=15, random_state=42)\n",
    "        emb_15d = pca.fit_transform(embeddings)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(emb_15d)\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "        unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "        cluster_centers_indices = {}\n",
    "        for cluster_label in unique_clusters:\n",
    "            cluster_centers_indices[cluster_label] = np.where(cluster_labels == cluster_label)[0][0]\n",
    "\n",
    "        tmp = []\n",
    "        for i in cluster_centers_indices.values():\n",
    "            tmp.append(i)\n",
    "        tmp.sort()\n",
    "\n",
    "        line1 = \"\"\n",
    "        core_sentences = []\n",
    "        for i in range(len(tmp) // 2):\n",
    "            line1 = line1 + corpus[tmp[i]] + f\" <extra_id_{i}>\"\n",
    "            core_sentences.append(corpus[tmp[i]])\n",
    "\n",
    "        line2 = \"\"\n",
    "        for i in range(len(tmp) // 2, len(tmp)):\n",
    "            line2 = line2 + corpus[tmp[i]] + f\" <extra_id_{i - len(tmp) // 2}>\"\n",
    "            core_sentences.append(corpus[tmp[i]])\n",
    "\n",
    "        lm_text = \"Заполни пробелы: \" + line1\n",
    "        input_ids = torch.tensor([tokenizer1.encode(lm_text)]).to(device)\n",
    "        outputs = model1.generate(input_ids, eos_token_id=tokenizer1.eos_token_id, early_stopping=True)\n",
    "        replace_dict = {\n",
    "            match.group(): replacement\n",
    "            for match, replacement in zip(re.finditer(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:])),\n",
    "                                          re.split(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:]))[1:])\n",
    "        }\n",
    "\n",
    "        def replacer(match):\n",
    "            return replace_dict.get(match.group(), '')\n",
    "\n",
    "        result1 = re.sub(r'<extra_id_\\d+>', replacer, line1)\n",
    "\n",
    "        lm_text = \"Заполни пробелы: \" + line2\n",
    "        input_ids = torch.tensor([tokenizer1.encode(lm_text)]).to(device)\n",
    "        outputs = model1.generate(input_ids, eos_token_id=tokenizer1.eos_token_id, early_stopping=True)\n",
    "        replace_dict = {\n",
    "            match.group(): replacement\n",
    "            for match, replacement in zip(re.finditer(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:])),\n",
    "                                          re.split(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:]))[1:])\n",
    "        }\n",
    "\n",
    "        def replacer(match):\n",
    "            return replace_dict.get(match.group(), '')\n",
    "\n",
    "        result2 = re.sub(r'<extra_id_\\d+>', replacer, line2)\n",
    "\n",
    "        final_line = result1 + result2\n",
    "\n",
    "        print(final_line)\n",
    "        return final_line\n",
    "\n",
    "\n",
    "    else:\n",
    "        video_data = video_dataframe(path_2_video, video_name, threshold=0.94, max_rectangle=40000)\n",
    "        tmp = top_words_list(video_data)\n",
    "        line1 = \"\"\n",
    "        core_sentences = []\n",
    "        for i in range(len(tmp) // 2):\n",
    "            line1 = line1 + tmp[i] + f\" <extra_id_{i}>\"\n",
    "            core_sentences.append(tmp[i])\n",
    "\n",
    "        line2 = \"\"\n",
    "        for i in range(len(tmp) // 2, len(tmp)):\n",
    "            line2 = line2 + tmp[i] + f\" <extra_id_{i - len(tmp) // 2}>\"\n",
    "            core_sentences.append(tmp[i])\n",
    "\n",
    "        lm_text = \"Заполни пробелы: \" + line1\n",
    "        input_ids = torch.tensor([tokenizer1.encode(lm_text)]).to(device)\n",
    "        outputs = model1.generate(input_ids, eos_token_id=tokenizer1.eos_token_id, early_stopping=True)\n",
    "        replace_dict = {\n",
    "            match.group(): replacement\n",
    "            for match, replacement in zip(re.finditer(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:])),\n",
    "                                          re.split(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:]))[1:])\n",
    "        }\n",
    "\n",
    "        def replacer(match):\n",
    "            return replace_dict.get(match.group(), '')\n",
    "\n",
    "        result1 = re.sub(r'<extra_id_\\d+>', replacer, line1)\n",
    "\n",
    "        lm_text = \"Заполни пробелы: \" + line2\n",
    "        input_ids = torch.tensor([tokenizer1.encode(lm_text)]).to(device)\n",
    "        outputs = model1.generate(input_ids, eos_token_id=tokenizer1.eos_token_id, early_stopping=True)\n",
    "        replace_dict = {\n",
    "            match.group(): replacement\n",
    "            for match, replacement in zip(re.finditer(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:])),\n",
    "                                          re.split(r'<extra_id_\\d+>', tokenizer1.decode(outputs[0][1:]))[1:])\n",
    "        }\n",
    "\n",
    "        def replacer(match):\n",
    "            return replace_dict.get(match.group(), '')\n",
    "\n",
    "        result2 = re.sub(r'<extra_id_\\d+>', replacer, line2)\n",
    "\n",
    "        final_line = result1 + result2\n",
    "        print(final_line)\n",
    "        return final_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cc7a8",
   "metadata": {},
   "source": [
    "## Визуализация кластеризации на n_components=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8dae49",
   "metadata": {},
   "source": [
    "![Кластеризация, при n_components](k-means_for_first_video.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfeaf7f",
   "metadata": {},
   "source": [
    "## Функции для расчёта метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9db45ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteor_metric(text, text_sum):\n",
    "    if isinstance(text_sum, str):\n",
    "        return round(meteor([word_tokenize(text)], word_tokenize(text_sum)), 4)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def bleu_metric(reference, hypothesis):\n",
    "    reference = [word_tokenize(reference)]\n",
    "    hypothesis = word_tokenize(hypothesis)\n",
    "    return round(sentence_bleu(reference, hypothesis), 4)\n",
    "\n",
    "\n",
    "def nist_metric(reference, hypothesis):\n",
    "    try:\n",
    "        reference = [word_tokenize(reference)]\n",
    "        hypothesis = word_tokenize(hypothesis)\n",
    "        return round(sentence_nist(reference, hypothesis), 4)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8dba1",
   "metadata": {},
   "source": [
    "## Инициализация алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "651e6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2csv = \"train.csv\"\n",
    "path2videos = \"train_video/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294bab31",
   "metadata": {},
   "source": [
    "## Результат работы алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddfb55e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:33<00:00,  2.61s/it]\n",
      "C:\\Users\\druzh\\Project_python\\venv\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\druzh\\Project_python\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Откуда на твоем лице прящи? Почему у одной девочки получается выглядеть женственно и эффектно, а у другой нет?    Ответ на этот вопрос может быть разным.  Возможно дело в ухоженности.    Конечно, красота - это не только Но никто не отменял такую вещь, как уход за собой. Это не только  элементарные нормы гигиены, но и способ  почувствовать себя еще красивее и привлекательнее. Во время пубертатного периода в организме  усиливается рост волос по всему телу.   Появляются прыщи.  Усиливается потливость. Если вдруг у тебя начали расти волосы там, где их раньше не было, или появились прыщи,   то это может быть связано с гормональными изменениями.  Изменения, которые происходят в организме подростка, они сильно зависят от количества витаминов и образа жизни.    Важную роль в этом играет питание. Чтобы избежать проблем с лишним весом кожей и волосами, важно правильно выставить  советую обсудить это с мамой. Она поможет тебе выбрать подходящие способы ухода за собой. При \n"
     ]
    }
   ],
   "source": [
    "data = process_corpus(path2csv)\n",
    "\n",
    "data[\"desc_proc\"] = data.apply(lambda x: calc(x.stt_sum, x.video_name, path2videos), axis=1)\n",
    "data[\"met\"] = data.apply(lambda x: meteor_metric(x.description, x.desc_proc), axis=1)\n",
    "data[\"nist\"] = data.apply(lambda x: nist_metric(x.description, x.desc_proc), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c030e7b",
   "metadata": {},
   "source": [
    "## Вывод метрик "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a73c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met:  [0.2391]\n",
      "met mean:  0.2391\n",
      "nist:  [0.5099]\n",
      "nist mean:  0.5099\n"
     ]
    }
   ],
   "source": [
    "print(\"met: \", data[\"met\"].values)\n",
    "print(\"met mean: \", data.met.mean())\n",
    "print(\"nist: \", data[\"nist\"].values)\n",
    "print(\"nist mean: \", data.nist.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
